{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61mb85_mbkr0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate\n",
        "!pip install openpyxl\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZnIi5OzFKwO"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Set the API token\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"api_token\"] = api_token\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.2-8b-instruct\"\n",
        "output = Replicate(\n",
        "model=model,\n",
        "replicate_api_token=api_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SKRIP REVISI 1\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files, userdata\n",
        "from langchain_community.llms import Replicate\n",
        "\n",
        "# === 1. Upload File Excel ===\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# === 2. Load Data ===\n",
        "df = pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
        "\n",
        "if \"Deskripsi\" not in df.columns:\n",
        "    raise ValueError(\"Kolom 'Deskripsi' tidak ditemukan di Sheet1\")\n",
        "\n",
        "# === 3. Set API Token ===\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "# === 4. Setup Model ===\n",
        "model = Replicate(\n",
        "    model=\"ibm-granite/granite-3.2-8b-instruct\",\n",
        "    replicate_api_token=api_token\n",
        ")\n",
        "\n",
        "# === 5. Prompt Template ===\n",
        "base_prompt = \"\"\"\n",
        "Classify the job descriptions in the \"Deskripsi\" column into three categories: \"hard skills\", \"soft skills\", and \"non-skills\".\n",
        "\n",
        "Definitions:\n",
        "- Hard skills: measurable abilities or knowledge areas that can be evaluated using performance indicators (examples: excel, SEO, digital marketing).\n",
        "- Soft skills: interpersonal or personal attributes that cannot be directly measured by KPIs but influence how people work (examples: communication, teamwork, leadership).\n",
        "- Non-skills: requirements that are neither hard skills nor soft skills (examples: degree, minimum age, years of experience).\n",
        "\n",
        "Rules:\n",
        "- Output must only contain three lines in this format:\n",
        "  hard skills: ...\n",
        "  soft skills: ...\n",
        "  non-skills: ...\n",
        "- Each tag must be maximum 2 words.\n",
        "- Do not write explanations or full sentences, only tags separated by commas.\n",
        "- Translate all tags into English if they are in Indonesian.\n",
        "- Extract skills or requirements directly from the text only. Do not invent or guess.\n",
        "- If no tag is found for a category, leave it blank after the colon.\n",
        "Text:\n",
        "\"\"\"\n",
        "\n",
        "# === 6. Process Each Row with Rate-Limit Handling ===\n",
        "hard_skills_list, soft_skills_list, non_skills_list = [], [], []\n",
        "\n",
        "for i, desc in enumerate(tqdm(df[\"Deskripsi\"], desc=\"Processing rows\")):\n",
        "    prompt = base_prompt + str(desc)\n",
        "\n",
        "    while True:  # retry loop jika kena rate limit\n",
        "        try:\n",
        "            result = model.invoke(\n",
        "                prompt,\n",
        "                top_k=5,\n",
        "                top_p=0.3,\n",
        "                temperature=0,\n",
        "                max_tokens=150,\n",
        "                min_tokens=30,\n",
        "                random_seed=42,\n",
        "                repetition_penalty=1.2,\n",
        "                stopping_sequence=[\"non-skills:\"]\n",
        "            )\n",
        "            break\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e):\n",
        "                print(f\"Rate limit reached at row {i+1}, waiting 15 seconds...\")\n",
        "                time.sleep(15)\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    # Parsing hasil\n",
        "    hs, ss, ns = \"\", \"\", \"\"\n",
        "    result_lower = result.lower()\n",
        "\n",
        "    if \"hard skills:\" in result_lower:\n",
        "        try:\n",
        "            hs = result.split(\"hard skills:\")[1].split(\"soft skills:\")[0].strip()\n",
        "        except:\n",
        "            pass\n",
        "    if \"soft skills:\" in result_lower:\n",
        "        try:\n",
        "            ss = result.split(\"soft skills:\")[1].split(\"non-skills:\")[0].strip()\n",
        "        except:\n",
        "            pass\n",
        "    if \"non-skills:\" in result_lower:\n",
        "        try:\n",
        "            ns = result.split(\"non-skills:\")[1].strip()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    hard_skills_list.append(hs)\n",
        "    soft_skills_list.append(ss)\n",
        "    non_skills_list.append(ns)\n",
        "\n",
        "    time.sleep(1)  # jeda kecil tiap request\n",
        "\n",
        "# === 7. Tambahkan ke DataFrame ===\n",
        "df[\"Hard Skills\"] = hard_skills_list\n",
        "df[\"Soft Skills\"] = soft_skills_list\n",
        "df[\"Non-Skills\"] = non_skills_list\n",
        "\n",
        "# === 8. Simpan & Download ===\n",
        "output_file = \"classified_skills_revisi_1_0.7.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "id": "MJ3uK_Wk5wmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESS KE-2 (REVISI 1)\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files, userdata\n",
        "from langchain_community.llms import Replicate\n",
        "\n",
        "# === 1. Upload File Excel Hasil Granite Sebelumnya ===\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "df = pd.read_excel(file_name)\n",
        "\n",
        "# Pastikan kolom hasil Granite ada\n",
        "for col in [\"Hard Skills\", \"Soft Skills\", \"Non-Skills\"]:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Kolom {col} tidak ditemukan di file Excel.\")\n",
        "\n",
        "# === 2. Ekstrak semua skill unik ===\n",
        "all_skills = set()\n",
        "\n",
        "def split_skills(cell):\n",
        "    if pd.isna(cell):\n",
        "        return []\n",
        "    return [s.strip() for s in str(cell).split(\",\") if s.strip()]\n",
        "\n",
        "for col in [\"Hard Skills\", \"Soft Skills\", \"Non-Skills\"]:\n",
        "    for val in df[col]:\n",
        "        all_skills.update(split_skills(val))\n",
        "\n",
        "all_skills = sorted(list(all_skills))\n",
        "\n",
        "print(f\"Total unique skills extracted: {len(all_skills)}\")\n",
        "\n",
        "# === 3. Setup Model ===\n",
        "api_token = userdata.get('api_token')\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "model = Replicate(\n",
        "    model=\"ibm-granite/granite-3.2-8b-instruct\",\n",
        "    replicate_api_token=api_token\n",
        ")\n",
        "\n",
        "# === 4. Prompt untuk Normalisasi ===\n",
        "base_prompt = \"\"\"\n",
        "You are given a list of skill tags separated by commas.\n",
        "Your task is to normalize them so that all variations, synonyms, or similar expressions are grouped into one consistent normalized tag.\n",
        "\n",
        "Rules:\n",
        "- Input list items are separated by commas.\n",
        "- Output format must only contain lines with \"original → normalized\".\n",
        "- If multiple items clearly refer to the same concept (e.g. \"degree\", \"bachelor’s degree\", \"management degree preferred\"), normalize them into one short consistent tag (max 2 words).\n",
        "- Always choose the most general base form, not the specific variation. Example: \"bachelor’s degree\", \"degree requirement\", \"management degree\" → \"degree\".\n",
        "- Normalize to English only.\n",
        "- Do not invent new tags, just unify.\n",
        "\n",
        "Now normalize the following list:\n",
        "\"\"\"\n",
        "\n",
        "skills_text = \"\\n\".join(all_skills)\n",
        "prompt = base_prompt + \"\\n\" + skills_text\n",
        "\n",
        "# === 5. Kirim ke Granite dengan Rate Limit Handling ===\n",
        "while True:\n",
        "    try:\n",
        "        result = model.invoke(\n",
        "            prompt,\n",
        "            top_k=1,\n",
        "            top_p=0.1,\n",
        "            temperature=0,\n",
        "            max_tokens=800,\n",
        "            min_tokens=30,\n",
        "            random_seed=42,\n",
        "            repetition_penalty=1.2,\n",
        "            stopping_sequence=None\n",
        "        )\n",
        "        break\n",
        "    except Exception as e:\n",
        "        if \"429\" in str(e):\n",
        "            print(\"Rate limit reached, waiting 15 seconds...\")\n",
        "            time.sleep(15)\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "print(\"=== Granite Normalization Output ===\")\n",
        "print(result)\n",
        "\n",
        "# === 6. Parsing hasil \"original → normalized\" ===\n",
        "mapping = {}\n",
        "for line in result.splitlines():\n",
        "    if \"→\" in line:\n",
        "        parts = line.split(\"→\")\n",
        "        if len(parts) == 2:\n",
        "            original = parts[0].strip().lower()\n",
        "            normalized = parts[1].strip().lower()\n",
        "            mapping[original] = normalized\n",
        "\n",
        "print(f\"\\nParsed {len(mapping)} mappings.\")\n",
        "\n",
        "# === 7. Apply Mapping ke DataFrame ===\n",
        "def normalize_cell(cell):\n",
        "    if pd.isna(cell):\n",
        "        return \"\"\n",
        "    skills = [s.strip().lower() for s in str(cell).split(\",\") if s.strip()]\n",
        "    normalized = [mapping.get(s, s) for s in skills]\n",
        "    # hapus duplikat & rapikan format\n",
        "    return \", \".join(sorted(set(normalized)))\n",
        "\n",
        "df[\"Hard Skills (Normalized)\"] = df[\"Hard Skills\"].apply(normalize_cell)\n",
        "df[\"Soft Skills (Normalized)\"] = df[\"Soft Skills\"].apply(normalize_cell)\n",
        "df[\"Non-Skills (Normalized)\"] = df[\"Non-Skills\"].apply(normalize_cell)\n",
        "\n",
        "# === 8. Simpan Hasil ===\n",
        "output_file = \"classified_skills_normalized_revisi_1_gabungan.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "id": "wbc0bGeHkVo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS KE-3\n",
        "# =========================\n",
        "# 1) Install & Import\n",
        "# =========================\n",
        "!pip install pandas openpyxl --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# =========================\n",
        "# 2) Upload & Read Excel\n",
        "# =========================\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Coba baca Sheet1; jika tidak ada, baca sheet pertama\n",
        "try:\n",
        "    df = pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
        "except Exception:\n",
        "    xls = pd.ExcelFile(file_name)\n",
        "    df = pd.read_excel(file_name, sheet_name=xls.sheet_names[0])\n",
        "\n",
        "print(\"Kolom tersedia:\", df.columns.tolist())\n",
        "\n",
        "# =========================\n",
        "# 3) Helper: clean & split\n",
        "# =========================\n",
        "def clean_tag(tag: str) -> str:\n",
        "    \"\"\"Lowercase, trim spasi, buang spasi berlebih.\"\"\"\n",
        "    tag = str(tag).strip().lower()\n",
        "    tag = re.sub(r\"\\s+\", \" \", tag)   # rapikan spasi ganda\n",
        "    return tag\n",
        "\n",
        "def explode_tags(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Ambil Series berisi string 'a, b, c', pecah jadi satu kolom berisi tag per baris,\n",
        "    bersihkan, dan buang kosong.\n",
        "    \"\"\"\n",
        "    vals = []\n",
        "    for cell in series.dropna():\n",
        "        # split berdasarkan koma\n",
        "        parts = [clean_tag(p) for p in str(cell).split(\",\")]\n",
        "        # buang tag kosong\n",
        "        parts = [p for p in parts if p]\n",
        "        vals.extend(parts)\n",
        "    return pd.Series(vals, dtype=\"string\")\n",
        "\n",
        "# =========================\n",
        "# 4) Hitung frekuensi per kategori\n",
        "# =========================\n",
        "target_cols = {\n",
        "    \"Hard Skills (Normalized)\":  \"Hard Skills (Frequency)\",\n",
        "    \"Soft Skills (Normalized)\":  \"Soft Skills (Frequency)\",\n",
        "    \"Non-Skills (Normalized)\":   \"Non-Skills (Frequency)\",\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for col, outname in target_cols.items():\n",
        "    if col not in df.columns:\n",
        "        print(f\"Peringatan: kolom '{col}' tidak ditemukan. Melewati kategori ini.\")\n",
        "        continue\n",
        "\n",
        "    exploded = explode_tags(df[col])\n",
        "    if exploded.empty:\n",
        "        freq_df = pd.DataFrame({\"skill_tag\": [], \"frequency\": []})\n",
        "    else:\n",
        "        freq_df = (exploded.value_counts()\n",
        "                   .rename_axis(\"skill_tag\")\n",
        "                   .reset_index(name=\"frequency\")\n",
        "                   .sort_values(\"frequency\", ascending=False)\n",
        "                   .reset_index(drop=True))\n",
        "\n",
        "    results[outname] = freq_df\n",
        "    # Ringkasan singkat\n",
        "    print(f\"\\nTop 10 {outname}\")\n",
        "    print(freq_df.head(10))\n",
        "\n",
        "# =========================\n",
        "# 5) Simpan ke Excel & download\n",
        "# =========================\n",
        "output_xlsx = \"skills_frequency.xlsx\"\n",
        "with pd.ExcelWriter(output_xlsx, engine=\"openpyxl\") as writer:\n",
        "    for sheet_name, freq_df in results.items():\n",
        "        # Nama sheet max 31 karakter (Excel)\n",
        "        safe_sheet = sheet_name[:31]\n",
        "        freq_df.to_excel(writer, index=False, sheet_name=safe_sheet)\n",
        "\n",
        "print(\"\\nFile tersimpan:\", output_xlsx)\n",
        "files.download(output_xlsx)\n"
      ],
      "metadata": {
        "id": "s7T4dM4f6_Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS KE-4 (EDGE LIST)\n",
        "\n",
        "# =========================\n",
        "# 1) Install & Import\n",
        "# =========================\n",
        "!pip install pandas openpyxl --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# =========================\n",
        "# 2) Upload & Read Excel\n",
        "# =========================\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Baca file\n",
        "try:\n",
        "    df = pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
        "except Exception:\n",
        "    xls = pd.ExcelFile(file_name)\n",
        "    df = pd.read_excel(file_name, sheet_name=xls.sheet_names[0])\n",
        "\n",
        "print(\"Kolom tersedia:\", df.columns.tolist())\n",
        "\n",
        "# =========================\n",
        "# 3) Helper untuk pecah skills\n",
        "# =========================\n",
        "def clean_tag(tag: str) -> str:\n",
        "    \"\"\"Bersihkan skill tag: lowercase + trim spasi\"\"\"\n",
        "    tag = str(tag).strip().lower()\n",
        "    tag = re.sub(r\"\\s+\", \" \", tag)  # rapikan spasi ganda\n",
        "    return tag\n",
        "\n",
        "def make_edge_list(df, col_pos, col_skill, skill_type=None):\n",
        "    \"\"\"Buat edge list dari kolom posisi dan kolom skill\"\"\"\n",
        "    edges = []\n",
        "    for _, row in df[[col_pos, col_skill]].dropna().iterrows():\n",
        "        pos = str(row[col_pos]).strip()\n",
        "        skills = [clean_tag(s) for s in str(row[col_skill]).split(\",\") if s.strip()]\n",
        "        for sk in skills:\n",
        "            if skill_type:\n",
        "                edges.append((pos, sk, skill_type))\n",
        "            else:\n",
        "                edges.append((pos, sk))\n",
        "    return edges\n",
        "\n",
        "# =========================\n",
        "# 4) Buat edge list per kategori\n",
        "# =========================\n",
        "target_cols = {\n",
        "    \"Hard Skills (Normalized)\":  (\"Edges_Hard_Skills\", \"hard\"),\n",
        "    \"Soft Skills (Normalized)\":  (\"Edges_Soft_Skills\", \"soft\"),\n",
        "    \"Non-Skills (Normalized)\":   (\"Edges_Non_Skills\", \"non-skill\"),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "all_edges = []\n",
        "\n",
        "for col, (sheet_name, skill_type) in target_cols.items():\n",
        "    if col not in df.columns:\n",
        "        print(f\"Peringatan: kolom '{col}' tidak ditemukan, dilewati.\")\n",
        "        continue\n",
        "\n",
        "    edges = make_edge_list(df, \"Posisi\", col, skill_type=skill_type)\n",
        "    df_edges = pd.DataFrame(edges, columns=[\"source\", \"target\", \"skill_type\"])\n",
        "    results[sheet_name] = df_edges[[\"source\", \"target\"]]  # versi tanpa skill_type untuk per sheet\n",
        "    all_edges.extend(edges)\n",
        "\n",
        "# =========================\n",
        "# 5) Simpan ke Excel\n",
        "# =========================\n",
        "output_xlsx = \"edge_list_skills.xlsx\"\n",
        "with pd.ExcelWriter(output_xlsx, engine=\"openpyxl\") as writer:\n",
        "    # Simpan per kategori (tanpa skill_type kolom)\n",
        "    for sheet_name, edges_df in results.items():\n",
        "        edges_df.to_excel(writer, index=False, sheet_name=sheet_name[:31])\n",
        "\n",
        "    # Simpan gabungan (dengan skill_type kolom)\n",
        "    all_edges_df = pd.DataFrame(all_edges, columns=[\"source\", \"target\", \"skill_type\"])\n",
        "    all_edges_df.to_excel(writer, index=False, sheet_name=\"All_Skills\")\n",
        "\n",
        "print(\"\\nFile tersimpan:\", output_xlsx)\n",
        "files.download(output_xlsx)\n"
      ],
      "metadata": {
        "id": "FVpLvnNaoc77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESS KE-4 EDGE LIST & NODE TABLES (REVISI 2)\n",
        "\n",
        "# =========================\n",
        "# 1) Install & Import\n",
        "# =========================\n",
        "!pip install pandas openpyxl --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "# =========================\n",
        "# 2) Upload & Read Excel\n",
        "# =========================\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Baca file: coba Sheet1, jika tidak ada pakai sheet pertama\n",
        "try:\n",
        "    df = pd.read_excel(file_name, sheet_name=\"Sheet1\")\n",
        "except Exception:\n",
        "    xls = pd.ExcelFile(file_name)\n",
        "    df = pd.read_excel(file_name, sheet_name=xls.sheet_names[0])\n",
        "\n",
        "print(\"Kolom tersedia:\", df.columns.tolist())\n",
        "\n",
        "# Validasi kolom wajib\n",
        "COL_POS = \"Posisi\"\n",
        "SKILL_COLS = [\"Hard Skills (Normalized)\", \"Soft Skills (Normalized)\", \"Non-Skills (Normalized)\"]\n",
        "\n",
        "if COL_POS not in df.columns:\n",
        "    raise ValueError(f\"Kolom wajib '{COL_POS}' tidak ditemukan.\")\n",
        "\n",
        "if not any(col in df.columns for col in SKILL_COLS):\n",
        "    raise ValueError(\"Minimal salah satu kolom skill (Hard/Soft/Non) harus ada.\")\n",
        "\n",
        "# =========================\n",
        "# 3) Helpers\n",
        "# =========================\n",
        "def clean_skill(tag: str) -> str:\n",
        "    \"\"\"Bersihkan skill tag: lowercase + trim spasi & spasi ganda.\"\"\"\n",
        "    tag = str(tag).strip().lower()\n",
        "    tag = re.sub(r\"\\s+\", \" \", tag)\n",
        "    return tag\n",
        "\n",
        "def split_skills(cell) -> list:\n",
        "    \"\"\"Pecah cell skill berdasarkan koma dan bersihkan.\"\"\"\n",
        "    if pd.isna(cell):\n",
        "        return []\n",
        "    parts = [p for p in str(cell).split(\",\")]\n",
        "    parts = [clean_skill(p) for p in parts]\n",
        "    return [p for p in parts if p]  # buang kosong\n",
        "\n",
        "def normalize_position(label: str) -> str:\n",
        "    \"\"\"Posisi: pakai label asli (trim), tidak di-lowercase agar terbaca enak di Gephi.\"\"\"\n",
        "    return str(label).strip()\n",
        "\n",
        "# =========================\n",
        "# 4) Konstruksi NODE ID (konsisten untuk posisi & skill)\n",
        "# =========================\n",
        "# Kumpulkan posisi unik\n",
        "pos_labels = df[COL_POS].dropna().map(normalize_position)\n",
        "pos_labels = pos_labels[pos_labels != \"\"].drop_duplicates().tolist()\n",
        "\n",
        "# Kumpulkan semua skill unik (gabungan 3 kolom)\n",
        "skill_labels = []\n",
        "for col in SKILL_COLS:\n",
        "    if col in df.columns:\n",
        "        for cell in df[col]:\n",
        "            skill_labels.extend(split_skills(cell))\n",
        "skill_labels = sorted(list(set(skill_labels)))  # lowercase sudah dari clean_skill\n",
        "\n",
        "# Buat ID map dengan namespace tipe node agar tidak bentrok\n",
        "# Key = (node_type, label)\n",
        "node_rows = []\n",
        "id_map = {}   # (node_type, label) -> id (int)\n",
        "\n",
        "next_id = 1\n",
        "\n",
        "# Assign ID untuk posisi\n",
        "for label in sorted(set(pos_labels)):   # sort agar deterministik\n",
        "    key = (\"posisi\", label)\n",
        "    id_map[key] = next_id\n",
        "    node_rows.append({\"Id\": next_id, \"Label\": label, \"node_type\": \"posisi\"})\n",
        "    next_id += 1\n",
        "\n",
        "# Assign ID untuk skills\n",
        "for label in skill_labels:\n",
        "    key = (\"skill\", label)\n",
        "    # Hindari tabrakan kalau (sangat jarang) ada posisi bernama sama persis dengan skill\n",
        "    if key not in id_map:\n",
        "        id_map[key] = next_id\n",
        "        node_rows.append({\"Id\": next_id, \"Label\": label, \"node_type\": \"skill\"})\n",
        "        next_id += 1\n",
        "\n",
        "nodes_all = pd.DataFrame(node_rows, columns=[\"Id\", \"Label\", \"node_type\"])\n",
        "\n",
        "# Split kembali nodes per tipe\n",
        "nodes_positions = nodes_all[nodes_all[\"node_type\"] == \"posisi\"].copy()\n",
        "nodes_skills    = nodes_all[nodes_all[\"node_type\"] == \"skill\"].copy()\n",
        "\n",
        "# Tambahan: peta referensi (node_type, label) -> id untuk debugging\n",
        "node_id_map = pd.DataFrame(\n",
        "    [{\"node_type\": k[0], \"label\": k[1], \"Id\": v} for k, v in id_map.items()],\n",
        "    columns=[\"node_type\", \"label\", \"Id\"]\n",
        ").sort_values([\"node_type\", \"label\"]).reset_index(drop=True)\n",
        "\n",
        "# =========================\n",
        "# 5) Bangun EDGE LIST (raw dan weighted) per kategori & gabungan\n",
        "# =========================\n",
        "def make_edges(df, col_pos, col_skill, skill_type: str):\n",
        "    \"\"\"Kembalikan list edge (Source, Target, Type, Weight=1, skill_type, source_label, target_label)\"\"\"\n",
        "    edges = []\n",
        "    sub = df[[col_pos, col_skill]].dropna(how=\"all\")\n",
        "    for _, row in sub.iterrows():\n",
        "        pos_label = normalize_position(row[col_pos])\n",
        "        if not pos_label:\n",
        "            continue\n",
        "        skills = split_skills(row[col_skill])\n",
        "        for sk in skills:\n",
        "            sid = id_map[(\"posisi\", pos_label)]\n",
        "            tid = id_map[(\"skill\", sk)]\n",
        "            edges.append({\n",
        "                \"Source\": sid,\n",
        "                \"Target\": tid,\n",
        "                \"Type\": \"Undirected\",\n",
        "                \"Weight\": 1,\n",
        "                \"skill_type\": skill_type,\n",
        "                \"source_label\": pos_label,\n",
        "                \"target_label\": sk\n",
        "            })\n",
        "    return edges\n",
        "\n",
        "# Kategori kolom -> (nama sheet dasar, skill_type)\n",
        "edge_conf = {\n",
        "    \"Hard Skills (Normalized)\": (\"Edges_Hard_Skills\", \"hard\"),\n",
        "    \"Soft Skills (Normalized)\": (\"Edges_Soft_Skills\", \"soft\"),\n",
        "    \"Non-Skills (Normalized)\":  (\"Edges_Non_Skills\", \"non-skill\"),\n",
        "}\n",
        "\n",
        "edges_sheets_raw = {}\n",
        "edges_sheets_weighted = {}\n",
        "all_edges_rows = []\n",
        "\n",
        "for col, (sheet_base, stype) in edge_conf.items():\n",
        "    if col not in df.columns:\n",
        "        print(f\"Peringatan: kolom '{col}' tidak ditemukan, dilewati.\")\n",
        "        continue\n",
        "    rows = make_edges(df, COL_POS, col, stype)\n",
        "    if not rows:\n",
        "        raw_df = pd.DataFrame(columns=[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\",\"source_label\",\"target_label\"])\n",
        "        w_df   = pd.DataFrame(columns=[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\"])\n",
        "    else:\n",
        "        raw_df = pd.DataFrame(rows)\n",
        "        raw_df.insert(0, \"Id\", [f\"{sheet_base}_E{i+1}\" for i in range(len(raw_df))])\n",
        "        # Weighted: gabungkan edge duplikat\n",
        "        w_df = (\n",
        "            raw_df\n",
        "            .groupby([\"Source\",\"Target\",\"Type\",\"skill_type\"], as_index=False)[\"Weight\"]\n",
        "            .sum()\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "        w_df.insert(0, \"Id\", [f\"{sheet_base}_W{i+1}\" for i in range(len(w_df))])\n",
        "        all_edges_rows.extend(rows)\n",
        "\n",
        "    edges_sheets_raw[sheet_base] = raw_df[[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\",\"source_label\",\"target_label\"]]\n",
        "    edges_sheets_weighted[sheet_base + \"_Weighted\"] = w_df[[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\"]]\n",
        "\n",
        "# Gabungan\n",
        "if all_edges_rows:\n",
        "    all_edges_raw = pd.DataFrame(all_edges_rows)\n",
        "    all_edges_raw.insert(0, \"Id\", [f\"ALL_E{i+1}\" for i in range(len(all_edges_raw))])\n",
        "    all_edges_weighted = (\n",
        "        all_edges_raw\n",
        "        .groupby([\"Source\",\"Target\",\"Type\",\"skill_type\"], as_index=False)[\"Weight\"]\n",
        "        .sum()\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    all_edges_weighted.insert(0, \"Id\", [f\"ALL_W{i+1}\" for i in range(len(all_edges_weighted))])\n",
        "else:\n",
        "    all_edges_raw = pd.DataFrame(columns=[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\",\"source_label\",\"target_label\"])\n",
        "    all_edges_weighted = pd.DataFrame(columns=[\"Id\",\"Source\",\"Target\",\"Type\",\"Weight\",\"skill_type\"])\n",
        "\n",
        "# =========================\n",
        "# 6) Tulis ke Excel & download\n",
        "# =========================\n",
        "output_xlsx = \"gephi_nodes_edges_weighted_consistent_ids.xlsx\"\n",
        "with pd.ExcelWriter(output_xlsx, engine=\"openpyxl\") as writer:\n",
        "    # Edges per kategori (raw & weighted)\n",
        "    for sheet_name, df_edges in edges_sheets_raw.items():\n",
        "        df_edges.to_excel(writer, index=False, sheet_name=sheet_name[:31])\n",
        "    for sheet_name, df_edges in edges_sheets_weighted.items():\n",
        "        df_edges.to_excel(writer, index=False, sheet_name=sheet_name[:31])\n",
        "\n",
        "    # Gabungan (raw & weighted)\n",
        "    all_edges_raw.to_excel(writer, index=False, sheet_name=\"All_Skills\")\n",
        "    all_edges_weighted.to_excel(writer, index=False, sheet_name=\"All_Skills_Weighted\")\n",
        "\n",
        "    # Nodes\n",
        "    nodes_positions.to_excel(writer, index=False, sheet_name=\"Nodes_Positions\")\n",
        "    nodes_skills.to_excel(writer, index=False, sheet_name=\"Nodes_Skills\")\n",
        "    nodes_all.to_excel(writer, index=False, sheet_name=\"Nodes_All\")\n",
        "\n",
        "    # Map referensi\n",
        "    node_id_map.to_excel(writer, index=False, sheet_name=\"Node_ID_Map\")\n",
        "\n",
        "print(\"\\nFile tersimpan:\", output_xlsx)\n",
        "files.download(output_xlsx)\n"
      ],
      "metadata": {
        "id": "0l6vEJpB-w5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}